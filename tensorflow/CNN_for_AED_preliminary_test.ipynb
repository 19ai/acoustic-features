{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_for_AED_preliminary_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nXwda0g5c8_g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine learning with TensorFlow: CNN\n",
        "\n",
        "Date: October 28, 2018\n",
        "\n",
        "Neural network: two convolution layers and three hidden layers\n",
        "\n",
        "Classification of acoustic events:\n",
        "- Piano music\n",
        "- Framenco guitar music\n",
        "- Classical guitar music\n",
        "- Blues hars music\n",
        "- Tin whistle music"
      ]
    },
    {
      "metadata": {
        "id": "V4VMbOvdLL7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATA_FOLDER = '/content/gdrive/My Drive/acoustic_event_detection/data/'\n",
        "FILTERS=40\n",
        "TRAINING_FILES = 16\n",
        "FILES = 24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5mp4dkJc8_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsSgFGjpc8_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing data set for training CNN"
      ]
    },
    {
      "metadata": {
        "id": "yuBXmB6ec8_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "piano_files = glob.glob(DATA_FOLDER+'*piano*melpsd*.csv')\n",
        "classical_guitar_files = glob.glob(DATA_FOLDER+'*classical_guitar*melpsd*.csv')\n",
        "framenco_guitar_files = glob.glob(DATA_FOLDER+'*framenco_guitar*melpsd*.csv')\n",
        "blues_harp_files = glob.glob(DATA_FOLDER+'*blues_harp*melpsd*.csv')\n",
        "tin_whistle_files = glob.glob(DATA_FOLDER+'*tin_whistle*melpsd*.csv')\n",
        "\n",
        "random.shuffle(piano_files)\n",
        "random.shuffle(classical_guitar_files)\n",
        "random.shuffle(framenco_guitar_files)\n",
        "random.shuffle(blues_harp_files)\n",
        "random.shuffle(tin_whistle_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SToK1ZDc8_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAINING_SET_PIANO = piano_files[:TRAINING_FILES]\n",
        "TRAINING_SET_CLASSICAL_GUITAR = classical_guitar_files[:TRAINING_FILES]\n",
        "TRAINING_SET_FRAMENCO_GUITAR = framenco_guitar_files[:TRAINING_FILES]\n",
        "TRAINING_SET_BLUES_HARP = blues_harp_files[:TRAINING_FILES]\n",
        "TRAINING_SET_TIN_WHISTLE = tin_whistle_files[:TRAINING_FILES]\n",
        "\n",
        "TEST_SET_PIANO = piano_files[TRAINING_FILES:FILES]\n",
        "TEST_SET_CLASSICAL_GUITAR = classical_guitar_files[TRAINING_FILES:FILES]\n",
        "TEST_SET_FRAMENCO_GUITAR = framenco_guitar_files[TRAINING_FILES:FILES]\n",
        "TEST_SET_BLUES_HARP = blues_harp_files[TRAINING_FILES:FILES]\n",
        "TEST_SET_TIN_WHISTLE = tin_whistle_files[TRAINING_FILES:FILES]\n",
        "\n",
        "TRAINING_SET = [(TRAINING_SET_PIANO, 0),\n",
        "                (TRAINING_SET_CLASSICAL_GUITAR, 1),\n",
        "                (TRAINING_SET_FRAMENCO_GUITAR, 2),\n",
        "                (TRAINING_SET_BLUES_HARP, 3),\n",
        "                (TRAINING_SET_TIN_WHISTLE, 4)]\n",
        "\n",
        "TEST_SET = [(TEST_SET_PIANO, 0),\n",
        "            (TEST_SET_CLASSICAL_GUITAR, 1),\n",
        "            (TEST_SET_FRAMENCO_GUITAR, 2),\n",
        "            (TEST_SET_BLUES_HARP, 3),\n",
        "            (TEST_SET_TIN_WHISTLE, 4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "8NYKy3I5c8_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_set = []\n",
        "test_set = []\n",
        "\n",
        "divider=FILTERS*100\n",
        "\n",
        "def label(l):\n",
        "    ll = [0,0,0,0,0]\n",
        "    ll[l] = 1\n",
        "    return ll\n",
        "\n",
        "for files, l in TRAINING_SET:\n",
        "    for file in files:\n",
        "        df = pd.read_csv(file.replace(os.path.sep, '/'), dtype=np.int16)\n",
        "        df = df[df['n']<FILTERS]\n",
        "        training_set.append((df[:divider], label(l)))\n",
        "        training_set.append((df[divider:], label(l)))\n",
        "        training_set.append((df[int(divider/2):divider+int(divider/2)], label(l)))\n",
        "        \n",
        "for files, l in TEST_SET:\n",
        "    for file in files:\n",
        "        df = pd.read_csv(file.replace(os.path.sep, '/'), dtype=np.int16)\n",
        "        df = df[df['n']<FILTERS]\n",
        "        test_set.append((df[:divider], label(l)))\n",
        "        test_set.append((df[divider:], label(l)))\n",
        "        test_set.append((df[int(divider/2):divider+int(divider/2)], label(l)))\n",
        "                        \n",
        "random.shuffle(training_set)\n",
        "random.shuffle(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_2FsqD-c8_5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x, train_t = [], []\n",
        "test_x, test_t = [], []\n",
        "for df, label in training_set:\n",
        "    values = df['magnitude'].values\n",
        "    train_x.append(values)\n",
        "    train_t.append(label)\n",
        "for df, label in test_set:\n",
        "    values = df['magnitude'].values\n",
        "    test_x.append(values)\n",
        "    test_t.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPhVfSm6c8_8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN on TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "LTeP4GyXc8__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(20181031)\n",
        "tf.set_random_seed(20181031)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-k_WbGOtgA1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolution layer"
      ]
    },
    {
      "metadata": {
        "id": "quFmcQM5c9AE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples = FILTERS * 100\n",
        "num_classes = 5\n",
        "\n",
        "num_filters1 = 128\n",
        "num_filters2 = 256\n",
        "\n",
        "num_layers = 1\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, FILTERS*100])\n",
        "x_image = tf.reshape(x, [-1,FILTERS,100,1])\n",
        "\n",
        "W_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, num_filters1], stddev=0.1))\n",
        "h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME')\n",
        "b_conv1 = tf.Variable(tf.constant(0.1, shape=[num_filters1]))\n",
        "h_conv1_cutoff = tf.nn.relu(h_conv1 + b_conv1)\n",
        "h_pool1 = tf.nn.max_pool(h_conv1_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "W_conv2 = tf.Variable(tf.truncated_normal([5, 5, num_filters1, num_filters2], stddev=0.1))\n",
        "h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding='SAME')\n",
        "b_conv2 = tf.Variable(tf.constant(0.1, shape=[num_filters2]))\n",
        "h_conv2_cutoff = tf.nn.relu(h_conv2 + b_conv2)\n",
        "h_pool2 = tf.nn.max_pool(h_conv2_cutoff, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "h_pool_flat2 = tf.reshape(h_pool2, [-1, int(FILTERS/4)*25*num_filters2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gn96f-MxgUm4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fully connected layer"
      ]
    },
    {
      "metadata": {
        "id": "QW7ODJU-c9AH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_units1 = int(FILTERS/4)*25*num_filters2\n",
        "num_units2 = 4096\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "w1 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))\n",
        "b1 = tf.Variable(tf.zeros([num_units2]))\n",
        "y1 = tf.matmul(h_pool_flat2, w1) + b1\n",
        "hidden1 = tf.nn.relu(y1)\n",
        "\n",
        "w2 = tf.Variable(tf.truncated_normal([num_units2, num_units2]))\n",
        "b2 = tf.Variable(tf.zeros([num_units2]))\n",
        "y2 = tf.matmul(hidden1, w2) + b2\n",
        "hidden2 = tf.nn.relu(y2)\n",
        "\n",
        "w3 = tf.Variable(tf.truncated_normal([num_units2, num_units2]))\n",
        "b3 = tf.Variable(tf.zeros([num_units2]))\n",
        "y3 = tf.matmul(hidden2, w3) + b3\n",
        "hidden3 = tf.nn.tanh(y3)\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "hidden3_drop = tf.nn.dropout(hidden3, keep_prob)\n",
        "\n",
        "w0 = tf.Variable(tf.zeros([num_units2, num_classes]))\n",
        "b0 = tf.Variable(tf.zeros([num_classes]))\n",
        "p = tf.nn.softmax(tf.matmul(hidden3_drop, w0) + b0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmTknDFrc9AJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = tf.placeholder(tf.float32, [None, num_classes])\n",
        "loss = -tf.reduce_sum(t * tf.log(p))\n",
        "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8YVIpxGc9AN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "ZO1xFC8tc9AQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for _ in range(1000):\n",
        "    i += 1\n",
        "    sess.run(train_step, feed_dict={x:train_x, t:train_t, keep_prob:0.5})\n",
        "    if i % 20 == 0:\n",
        "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={x:test_x, t:test_t, keep_prob:1.0})\n",
        "        print('Step: {}, Loss: {}, Accuracy: {}'.format(i, loss_val, acc_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ANUod5YAgtpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Confirmation with test data set"
      ]
    },
    {
      "metadata": {
        "id": "gqFLH2SSc9AV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p_test = sess.run(p, feed_dict={x:test_x, keep_prob:1.0})\n",
        "(p_test*100).astype(int)[:16]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIfvyRp2c9AY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_t[:16]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u4XLTiEQc9Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CouFsxRzc9Ae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}